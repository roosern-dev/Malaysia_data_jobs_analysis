{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scraping script for obtaining data on data related jobs in Malaysia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "#from selenium import webdriver\n",
    "from bs4 import BeautifulSoup\n",
    "#from webdriver_manager.chrome import ChromeDriverManager\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import re\n",
    "import os\n",
    "from lxml import etree\n",
    "import lxml.html, lxml.html.clean\n",
    "from urllib.parse import urlparse\n",
    "from urllib.parse import parse_qs\n",
    "import pandas as pd\n",
    "from itertools import product\n",
    "import time\n",
    "\n",
    "\n",
    "#driver = webdriver.Chrome(ChromeDriverManager().install())\n",
    "verbose_flag = True\n",
    "# htmlSource = driver.page_source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_engineer_site = r'https://www.jobstreet.com.my/en/job-search/data-engineer-jobs/'\n",
    "main_site=r\"https://www.jobstreet.com.my\"\n",
    "\n",
    "page = requests.get(data_engineer_site)\n",
    "\n",
    "soup = BeautifulSoup(page.content, 'html.parser')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find number of result pages\n",
    "results = soup.find('select', attrs={\"id\":\"pagination\"})\n",
    "options = results.find_all('option')\n",
    "\n",
    "num_result_pages = int(options[-1]['value'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "jobslist = soup.find('div', attrs={'id':\"jobList\"}).find('div', attrs={'data-automation':'jobListing'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "jobs = jobslist.find_all('a', attrs={'class':'_1hr6tkx5 _1hr6tkx8 _1hr6tkxb sx2jih0 sx2jihf zcydq8h', 'href': re.compile(r'^\\/en\\/job\\/')})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "joblink = jobs[29].get('href')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_fulllink = main_site + joblink\n",
    "#job_fulllink = r\"https://www.jobstreet.com.my/en/job/data-engineer-4834504?jobId=jobstreet-my-job-4834504&sectionRank=1&token=0~9d2b2714-12eb-4e27-b40c-24f3babd0c52&fr=SRP%20View%20In%20New%20Tab\"\n",
    "job_page = requests.get(job_fulllink)\n",
    "\n",
    "job_soup = BeautifulSoup(job_page.content, 'html.parser')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['jobstreet-sg-job-9340168']\n"
     ]
    }
   ],
   "source": [
    "parsed_url = urlparse(job_fulllink)\n",
    "captured_value = parse_qs(parsed_url.query)\n",
    "print(captured_value['jobId'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "jobs_dom = etree.HTML(str(job_soup))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "job:  Data Engineer / Senior Data Engineer - MY\n",
      "company:  AZENDIAN SOLUTIONS PTE. LTD.\n",
      "salary range:  Posted on 3-Mar-22\n",
      "job description:  The RoleWe are looking for a qualified Data Engineer who will be part of the data engineering team. The ideal candidate will design and develop high quality data products - data warehouse, data marts, data lake data hubs and dashboards; either on cloud or on-premises system environments. Responsibilities:Build and support the data pipeline and all the associated Software Engineering infrastructure tasks.Liaise with clients, technical architects, data architects, data scientists and BI analysts to gather the requirements.Analyse the data requirements, prepare the functional and non-functional specifications for the data products.Develop the data pipeline using either ETL/ELT approach to load or synchronise data in near real time or batch mode.Analyse and interpret data into business insights.  Design and develop the dashboards and visualizations using the BI tools.Ability to understand and convert the business logics into SQL queries and validate it against the data.Prepare the Test Plans and conduct Unit Testing, System Integration Test, User Acceptance Test and Performance Test.Implement the deployment approaches and methods to roll-out the system changes.Stay up to date with industry standards and technological advancements that will improve the quality of the data products.Requirements:Minimum bachelor’s degree in Computer Science or related fields.At least 3 years of end-to-end data warehouse, data lake and big data implementation experience.Proficient with at least one or more of the following technologies: Informatica ETL Tools, SSIS, SQL Skills, SQL Server, Azure Data Factory, Data Warehouse, ETL Framework.Preferably possess a good knowledge about: Power BI, Qliksense, MicroStrategy, SAS and Tableau.Preferably possess a good knowledge about: DataStage, Attunity, Hadoop Ecosystem, Data APIs, Unstructured Data and Data Modelling.Manage and coach a team to achieve project objectives.Able to lead multiple teams and effectively work under pressure when there is an escalated demand in the project lifecycle.Understand the solution requirements and progress to design, develop, build and eventual operationalising the solutions.Enjoy problem solving in the different domains and industries.Love working with a highly energetic and competent team.A self-starter with an analytical approach to problem solving.A client-centric, outcome driven and quality focused team player.Excellent communication skills; both in written and spoken English.\n"
     ]
    }
   ],
   "source": [
    "job_title = jobs_dom.xpath('//*[@id=\"contentContainer\"]/div/div[1]/div[1]/div[1]/div/div/div[1]/div/div/div[2]/div/div/div/div[1]/h1')[0].text\n",
    "company_name = jobs_dom.xpath('//*[@id=\"contentContainer\"]/div/div[1]/div[1]/div[1]/div/div/div[1]/div/div/div[2]/div/div/div/div[2]/span')[0].text\n",
    "salary_range = jobs_dom.xpath('//*[@id=\"contentContainer\"]/div/div[1]/div[1]/div[1]/div/div/div[2]/div/div/div/div[2]/span')[0].text\n",
    "\n",
    "cleaner = lxml.html.clean.Cleaner(allow_tags=[''])\n",
    "cleaned = cleaner.clean_html(etree.tostring(jobs_dom.xpath('//*[@id=\"contentContainer\"]/div/div[2]/div/div[1]/div/div[1]/div/div[2]/div/span/div')[0]))\n",
    "print()\n",
    "job_description = cleaned.decode(\"utf-8\").replace('<div>', '').replace('</div>','')\n",
    "#job_description = etree.tostring(jobs_dom.xpath('//*[@id=\"contentContainer\"]/div/div[2]/div/div[1]/div/div[2]/div/div[2]/div/span/div')[0])\n",
    "# job_level = jobs_dom.xpath('//*[@id=\"contentContainer\"]/div/div[2]/div/div[1]/div/div[2]/div/div[2]/div/div/div[1]/div/div/div[2]/span')[0].text\n",
    "# years_experience = jobs_dom.xpath('//*[@id=\"contentContainer\"]/div/div[2]/div/div[1]/div/div[2]/div/div[2]/div/div/div[3]/div/div/div[2]/span')[0].text\n",
    "# qualifications = jobs_dom.xpath('//*[@id=\"contentContainer\"]/div/div[2]/div/div[1]/div/div[2]/div/div[2]/div/div/div[3]/div/div/div[2]/span')[0].text\n",
    "# job_type = jobs_dom.xpath('//*[@id=\"contentContainer\"]/div/div[2]/div/div[1]/div/div[2]/div/div[2]/div/div/div[4]/div/div/div[2]/span')[0].text\n",
    "# company_registration = jobs_dom.xpath('//*[@id=\"contentContainer\"]/div/div[2]/div/div[2]/div[2]/div[2]/div/div[2]/div/div/div[1]/div/div/div[2]/span')[0].text\n",
    "# company_size = jobs_dom.xpath('//*[@id=\"contentContainer\"]/div/div[2]/div/div[2]/div[2]/div[2]/div/div[2]/div/div/div[1]/div/div/div[2]/span')[0].text\n",
    "# industry_type = jobs_dom.xpath('//*[@id=\"contentContainer\"]/div/div[2]/div/div[2]/div[2]/div[2]/div/div[2]/div/div/div[1]/div/div/div[2]/span')[0].text\n",
    "# location = jobs_dom.xpath('//*[@id=\"contentContainer\"]/div/div[1]/div[1]/div[1]/div/div/div[2]/div/div/div/div[1]/div/span')[0].text\n",
    "\n",
    "if verbose_flag:\n",
    "    print('job: ', job_title)\n",
    "    print('company: ', company_name)\n",
    "    print(\"salary range: \", salary_range)\n",
    "    print('job description: ', job_description)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for job in jobs_dom.xpath('//*[@id=\"contentContainer\"]/div/div[2]/div/div[1]/div/div[1]/div/div[2]/div/span/div/div'):\n",
    "    print(etree.tostring(job))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_4564/553110362.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mcleaner\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlxml\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhtml\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclean\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCleaner\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mallow_tags\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m''\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mcleaned\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcleaner\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclean_html\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0metree\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtostring\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjobs_dom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mxpath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'//*[@id=\"contentContainer\"]/div/div[2]/div/div[1]/div/div[1]/div/div[2]/div/span/div/div'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcleaned\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"utf-8\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'<div>'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m''\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'</div>'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m''\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "cleaner = lxml.html.clean.Cleaner(allow_tags=[''])\n",
    "cleaned = cleaner.clean_html(etree.tostring(jobs_dom.xpath('//*[@id=\"contentContainer\"]/div/div[2]/div/div[1]/div/div[1]/div/div[2]/div/span/div/div')[0]))\n",
    "print(cleaned.decode(\"utf-8\").replace('<div>', '').replace('</div>',''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(etree.tostring(job_description))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_title = employer_details.find('h1', attrs={'class':'sx2jih0 _18qlyvc0 _18qlyvch _1d0g9qk4 _18qlyvcp _18qlyvc1x'}).text\n",
    "print(job_title)\n",
    "company = employer_details.find('span', attrs={'class':'sx2jih0 zcydq84u _18qlyvc0 _18qlyvc1x _18qlyvc2 _1d0g9qk4 _18qlyvcb'}).text\n",
    "print(company)\n",
    "salary_range = employer_details.findAll('span', attrs={'class':'sx2jih0 zcydq84u _18qlyvc0 _18qlyvc1x _18qlyvc1 _18qlyvca'}).\n",
    "print(salary_range)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Definition of scraping functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search(keyword:str, region:str, retry = 0) -> list:\n",
    "    '''\n",
    "        search jobstreet for keyword, returns results as a list of job results\n",
    "    '''\n",
    "    try:\n",
    "        if(retry > 20):\n",
    "            raise Exception(\"Too many retries, endpoint notreachable\")\n",
    "\n",
    "        search_term = keyword.replace(' ', '-')\n",
    "        root_link = r'https://www.jobstreet.com.my/en/job-search/'\n",
    "        search_link = root_link + search_term + '-jobs' + \"-in-\" + region\n",
    "        page = requests.get(search_link)\n",
    "        if(page.status_code != 200):\n",
    "                time.sleep(2)\n",
    "                return search(keyword, region, retry + 1)\n",
    "        soup = BeautifulSoup(page.content, 'html.parser')\n",
    "        results = soup.find('select', attrs={\"id\":\"pagination\"})\n",
    "        if(results is not None):\n",
    "            options = results.find_all('option')\n",
    "            num_result_pages = int(options[-1]['value'])\n",
    "        else:\n",
    "            num_result_pages = 1\n",
    "        print(f\"searching @ {search_link}\")\n",
    "        print(f\"total results pages for search {keyword}:\", {str(num_result_pages)})\n",
    "\n",
    "        all_results = []\n",
    "        print(\"scraping page 1...\")\n",
    "        first_page_results = get_job_links(search_link)\n",
    "        all_results = all_results + first_page_results\n",
    "\n",
    "        #get the rest of the result pages\n",
    "        if(num_result_pages > 1):\n",
    "            for page in range(2, num_result_pages+1):\n",
    "                print(f\"scraping page {page}...\")\n",
    "                search_page = search_link + '/' + str(page)\n",
    "                results_job_links = get_job_links(search_page)\n",
    "                all_results = all_results + results_job_links\n",
    "\n",
    "        print(\"done!\")\n",
    "        return(all_results)\n",
    "\n",
    "    except  Exception as e:\n",
    "        print(e)\n",
    "    \n",
    "\n",
    "\n",
    "def get_job_links(page_link:str, retry=0) -> list:\n",
    "    try:\n",
    "        if(retry > 20):\n",
    "            raise Exception(\"Too many retries, endpoint notreachable\")\n",
    "\n",
    "        results_job_links = []\n",
    "        page = requests.get(page_link)\n",
    "        if(page.status_code != 200):\n",
    "                time.sleep(2)\n",
    "                return get_job_links(page_link, retry + 1)\n",
    "        soup = BeautifulSoup(page.content, 'html.parser')\n",
    "        if(soup is None):\n",
    "            return None\n",
    "        jobs_list = soup.find('div', attrs={'id':\"jobList\"}).find('div', attrs={'data-automation':'jobListing'})\n",
    "        jobs = jobs_list.find_all('a', attrs={'class':'_1hr6tkx5 _1hr6tkx8 _1hr6tkxb sx2jih0 sx2jihf zcydq8h', 'href': re.compile(r'^\\/en\\/job\\/')})\n",
    "        for job in jobs:\n",
    "            job_link = job.get('href')\n",
    "            results_job_links.append(job_link)\n",
    "\n",
    "        return results_job_links\n",
    "\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "\n",
    "\n",
    "def extract_job_details(job_page_link:str, retry = 0)->dict:\n",
    "    try:\n",
    "        if(retry > 20):\n",
    "            raise Exception(\"Too many retries, endpoint notreachable\")\n",
    "\n",
    "        root_link = r\"https://www.jobstreet.com.my\"\n",
    "        full_link = root_link + job_page_link\n",
    "        parsed_url = urlparse(full_link)\n",
    "        captured_value = parse_qs(parsed_url.query)\n",
    "        \n",
    "        jobID = captured_value['jobId']\n",
    "        \n",
    "        job_page = requests.get(full_link)\n",
    "        if(job_page.status_code != 200):\n",
    "            time.sleep(2)\n",
    "            return extract_job_details(job_page_link, retry+1)\n",
    "        job_soup = BeautifulSoup(job_page.content, 'html.parser')\n",
    "        if(job_soup is None):\n",
    "            raise Exception(\"No results\")\n",
    "        \n",
    "        jobs_dom = etree.HTML(str(job_soup))\n",
    "        job_title = jobs_dom.xpath('//*[@id=\"contentContainer\"]/div/div[1]/div[1]/div[1]/div/div/div[1]/div/div/div[2]/div/div/div/div[1]/h1')[0].text\n",
    "        salary_range = jobs_dom.xpath('//*[@id=\"contentContainer\"]/div/div[1]/div[1]/div[1]/div/div/div[2]/div/div/div/div[2]/span')[0].text\n",
    "\n",
    "        cleaner = lxml.html.clean.Cleaner(allow_tags=[''])\n",
    "        cleaned = cleaner.clean_html(etree.tostring(jobs_dom.xpath('//*[@id=\"contentContainer\"]/div/div[2]/div/div[1]/div')[0]))\n",
    "                                                                    #//*[@id=\"contentContainer\"]/div/div[2]/div/div[1]/div/div[1]/div/div[2]/div/span/div\n",
    "        job_description = cleaned.decode(\"utf-8\").replace('<div>', '').replace('</div>','')\n",
    "        job_level = job_soup.find('span', string=\"Career Level\")\n",
    "        if(job_level is not None):\n",
    "            job_level = list(list(job_level.parent.parent.children)[1].children)[0].text    \n",
    "\n",
    "        experience = job_soup.find('span', string=\"Years of Experience\")\n",
    "        if (experience is not None):                 \n",
    "            experience = list(list(experience.parent.parent.children)[1].children)[0].text    \n",
    "\n",
    "        job_type = job_soup.find('span', string=\"Job Type\")\n",
    "        if(job_type is not None):\n",
    "            job_type = list(list(job_type.parent.parent.children)[1].children)[0].text \n",
    "\n",
    "        qualifications = job_soup.find('span', string=\"Qualification\")\n",
    "        if(qualifications is not None):\n",
    "            qualifications = list(list(qualifications.parent.parent.children)[1].children)[0].text\n",
    "\n",
    "        job_specialization = job_soup.find('span', string=\"Job Specializations\")\n",
    "        if(job_specialization is not None):\n",
    "            job_specialization = list(list(job_specialization.parent.parent.children)[1].children)[0].text\n",
    "\n",
    "\n",
    "        company_name = jobs_dom.xpath('//*[@id=\"contentContainer\"]/div/div[1]/div[1]/div[1]/div/div/div[1]/div/div/div[2]/div/div/div/div[2]/span')[0].text\n",
    "        company_registration = job_soup.find('span', string=\"Registration No.\")\n",
    "        if(company_registration is not None):\n",
    "            company_registration = list(list(company_registration.parent.parent.children)[1].children)[0].text\n",
    "\n",
    "        company_size = job_soup.find('span', string=\"Company Size\")\n",
    "        if(company_size is not None):\n",
    "            company_size = list(list(company_size.parent.parent.children)[1].children)[0].text\n",
    "\n",
    "        company_industry = job_soup.find('span', string=\"Industry\")\n",
    "        if(company_industry is not None):\n",
    "            company_industry = list(list(list(company_industry.parent.parent.children)[1].children)[0].children)[0].text\n",
    "        \n",
    "        return {\"job_id\":jobID, 'job_title': job_title, \"salary_range\":salary_range, \"job_description\":job_description, \"job_level\":job_level, \"experience\":experience, \"job_type\":job_type, \"qualifications\":qualifications, 'job_specialization':job_specialization, 'company_name':company_name, 'company_registration':company_registration, \"company_size\":company_size, \"company_industry\":company_industry}\n",
    "    \n",
    "    except Exception as e:\n",
    "        print('exception caught!', str(e))\n",
    "        print(job_page.status_code)\n",
    "        return {\"job_id\":None, 'job_title': None, \"salary_range\":None, \"job_description\":None, \"job_level\":None, \"experience\":None, \"job_type\":None, \"qualifications\":None, 'job_specialization':None, 'company_name':None, 'company_registration':None, \"company_size\":None, \"company_industry\":None}\n",
    "\n",
    "def get_job_page(job_page_link:str):\n",
    "    root_link = r\"https://www.jobstreet.com.my\"\n",
    "    full_link = root_link + job_page_link\n",
    "    job_page = requests.get(full_link)\n",
    "    job_soup = BeautifulSoup(job_page.content, 'html.parser')\n",
    "    parsed_url = urlparse(job_fulllink)\n",
    "    captured_value = parse_qs(parsed_url.query)\n",
    "    \n",
    "    job_ID = captured_value['jobId']\n",
    "\n",
    "    return {'job_ID': job_ID, 'page':page.content}\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns=['a', 'b', 'c'])\n",
    "\n",
    "data1 = {'a':1, 'b':2, 'c':3}\n",
    "data2 = {'a':4, 'b':5, 'c':6}\n",
    "\n",
    "df = df.append(data1, ignore_index=True)\n",
    "df = df.append(data2, ignore_index=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data scientist negeri-sembilan\n",
      "searching @ https://www.jobstreet.com.my/en/job-search/data-scientist-jobs-in-negeri-sembilan\n",
      "total results pages for search data scientist: {'1'}\n",
      "scraping page 1...\n",
      "done!\n",
      "data scientist kedah\n",
      "searching @ https://www.jobstreet.com.my/en/job-search/data-scientist-jobs-in-kedah\n",
      "total results pages for search data scientist: {'2'}\n",
      "scraping page 1...\n",
      "scraping page 2...\n",
      "done!\n",
      "data scientist pahang\n",
      "searching @ https://www.jobstreet.com.my/en/job-search/data-scientist-jobs-in-pahang\n",
      "total results pages for search data scientist: {'1'}\n",
      "scraping page 1...\n",
      "done!\n",
      "data scientist perak\n",
      "searching @ https://www.jobstreet.com.my/en/job-search/data-scientist-jobs-in-perak\n",
      "total results pages for search data scientist: {'1'}\n",
      "scraping page 1...\n",
      "done!\n",
      "data scientist selangor\n",
      "searching @ https://www.jobstreet.com.my/en/job-search/data-scientist-jobs-in-selangor\n",
      "total results pages for search data scientist: {'27'}\n",
      "scraping page 1...\n",
      "scraping page 2...\n",
      "scraping page 3...\n",
      "scraping page 4...\n",
      "scraping page 5...\n",
      "scraping page 6...\n",
      "scraping page 7...\n",
      "scraping page 8...\n",
      "scraping page 9...\n",
      "scraping page 10...\n",
      "scraping page 11...\n",
      "scraping page 12...\n",
      "scraping page 13...\n",
      "scraping page 14...\n",
      "scraping page 15...\n",
      "scraping page 16...\n",
      "scraping page 17...\n",
      "scraping page 18...\n",
      "scraping page 19...\n",
      "scraping page 20...\n",
      "scraping page 21...\n",
      "scraping page 22...\n",
      "scraping page 23...\n",
      "scraping page 24...\n",
      "scraping page 25...\n",
      "scraping page 26...\n",
      "scraping page 27...\n",
      "done!\n",
      "data scientist sabah\n",
      "searching @ https://www.jobstreet.com.my/en/job-search/data-scientist-jobs-in-sabah\n",
      "total results pages for search data scientist: {'1'}\n",
      "scraping page 1...\n",
      "done!\n",
      "data scientist johor\n",
      "searching @ https://www.jobstreet.com.my/en/job-search/data-scientist-jobs-in-johor\n",
      "total results pages for search data scientist: {'4'}\n",
      "scraping page 1...\n",
      "scraping page 2...\n",
      "scraping page 3...\n",
      "scraping page 4...\n",
      "done!\n",
      "data scientist sarawak\n",
      "searching @ https://www.jobstreet.com.my/en/job-search/data-scientist-jobs-in-sarawak\n",
      "total results pages for search data scientist: {'2'}\n",
      "scraping page 1...\n",
      "scraping page 2...\n",
      "done!\n",
      "data scientist terengganu\n",
      "searching @ https://www.jobstreet.com.my/en/job-search/data-scientist-jobs-in-terengganu\n",
      "total results pages for search data scientist: {'1'}\n",
      "scraping page 1...\n",
      "done!\n",
      "data scientist perlis\n",
      "searching @ https://www.jobstreet.com.my/en/job-search/data-scientist-jobs-in-perlis\n",
      "total results pages for search data scientist: {'1'}\n",
      "scraping page 1...\n",
      "done!\n",
      "data scientist kelantan\n",
      "searching @ https://www.jobstreet.com.my/en/job-search/data-scientist-jobs-in-kelantan\n",
      "total results pages for search data scientist: {'1'}\n",
      "scraping page 1...\n",
      "done!\n",
      "data scientist melaka\n",
      "searching @ https://www.jobstreet.com.my/en/job-search/data-scientist-jobs-in-melaka\n",
      "total results pages for search data scientist: {'2'}\n",
      "scraping page 1...\n",
      "scraping page 2...\n",
      "done!\n",
      "data scientist penang\n",
      "searching @ https://www.jobstreet.com.my/en/job-search/data-scientist-jobs-in-penang\n",
      "total results pages for search data scientist: {'13'}\n",
      "scraping page 1...\n",
      "scraping page 2...\n",
      "scraping page 3...\n",
      "scraping page 4...\n",
      "scraping page 5...\n",
      "scraping page 6...\n",
      "scraping page 7...\n",
      "scraping page 8...\n",
      "scraping page 9...\n",
      "scraping page 10...\n",
      "scraping page 11...\n",
      "scraping page 12...\n",
      "scraping page 13...\n",
      "done!\n",
      "data scientist kuala-lumpur\n",
      "searching @ https://www.jobstreet.com.my/en/job-search/data-scientist-jobs-in-kuala-lumpur\n",
      "total results pages for search data scientist: {'35'}\n",
      "scraping page 1...\n",
      "scraping page 2...\n",
      "scraping page 3...\n",
      "scraping page 4...\n",
      "scraping page 5...\n",
      "scraping page 6...\n",
      "scraping page 7...\n",
      "scraping page 8...\n",
      "scraping page 9...\n",
      "scraping page 10...\n",
      "scraping page 11...\n",
      "scraping page 12...\n",
      "scraping page 13...\n",
      "scraping page 14...\n",
      "scraping page 15...\n",
      "scraping page 16...\n",
      "scraping page 17...\n",
      "scraping page 18...\n",
      "scraping page 19...\n",
      "scraping page 20...\n",
      "scraping page 21...\n",
      "scraping page 22...\n",
      "scraping page 23...\n",
      "scraping page 24...\n",
      "scraping page 25...\n",
      "scraping page 26...\n",
      "scraping page 27...\n",
      "scraping page 28...\n",
      "scraping page 29...\n",
      "scraping page 30...\n",
      "scraping page 31...\n",
      "scraping page 32...\n",
      "scraping page 33...\n",
      "scraping page 34...\n",
      "scraping page 35...\n",
      "done!\n"
     ]
    }
   ],
   "source": [
    "states = [\"negeri-sembilan\", \"kedah\", \"pahang\", \"perak\", \"selangor\", \"sabah\", \"johor\", \"sarawak\", \"terengganu\", \"perlis\", \"kelantan\", \"melaka\", \"penang\", \"kuala-lumpur\"]\n",
    "#states = [\"selangor\"]\n",
    "#job_search_terms = [\"data engineer\", \"data scientist\", \"data analyst\"]\n",
    "job_search_terms = ['data scientist']\n",
    "\n",
    "columns = [\"job_id\", 'job_title', \"salary_range\", \"job_description\", \"job_level\", \"experience\", \"job_type\", \"qualifications\", 'job_specialization', 'company_name', 'company_registration', \"company_size\", \"company_industry\", \"job_link\", \"search_term\", \"state\"]\n",
    "jobs_df = pd.DataFrame(columns=columns)\n",
    "\n",
    "\n",
    "for search_term, state in product(job_search_terms, states):\n",
    "    print(search_term, state)\n",
    "    results = search(search_term, state)\n",
    "\n",
    "    for job_link in results:\n",
    "        time.sleep(0.2)\n",
    "        job_details = extract_job_details(job_link)\n",
    "        job_details['job_link'] = job_link\n",
    "        job_details['search_term'] = search_term\n",
    "        job_details['state'] = state\n",
    "\n",
    "        jobs_df = jobs_df.append(job_details, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r\"C:\\Users\\RSYeo\\Projects\\data\\data_scientist_2022_03_08.ftr\"\n",
    "jobs_df.to_feather(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jobs_df2 = pd.read_feather(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jobs_df.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "JD = extract_job_details(results[1])\n",
    "JD2 = extract_job_details(results[3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(JD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.append(JD2, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "page = requests.get(r\"https://www.jobstreet.com.my/en/job/assistant-vice-president-data-engineer-compliance-amlt-remediation-4824511?fr=SRP%20Job%20Listing&jobId=jobstreet-my-job-4824511&sectionRank=2&token=0~2cdf76e9-a859-4c15-bb9a-e16a948b507a\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(page.content, 'html.parser')\n",
    "list(list(soup.find('span', string=\"Career Level\").parent.parent.children)[1].children)[0].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_job_details('/en/job/data-scientist-9316926/origin/sg?jobId=jobstreet-sg-job-9316926&sectionRank=30&token=0~474bcf85-700c-437e-8294-235da1e78670&fr=SRP%20Job%20Listing')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_data_scientist = r\"C:\\Users\\RSYeo\\Projects\\data\\data_scientist_2022_03_02.ftr\"\n",
    "path_data_engineer =r\"C:\\Users\\RSYeo\\Projects\\data\\data_engineer_2022_03_02.ftr\"\n",
    "path_data_analyst = r\"C:\\Users\\RSYeo\\Projects\\data\\data_analyst_2022_03_02.ftr\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_id</th>\n",
       "      <th>job_title</th>\n",
       "      <th>salary_range</th>\n",
       "      <th>job_description</th>\n",
       "      <th>job_level</th>\n",
       "      <th>experience</th>\n",
       "      <th>job_type</th>\n",
       "      <th>qualifications</th>\n",
       "      <th>job_specialization</th>\n",
       "      <th>company_name</th>\n",
       "      <th>company_registration</th>\n",
       "      <th>company_size</th>\n",
       "      <th>company_industry</th>\n",
       "      <th>job_link</th>\n",
       "      <th>search_term</th>\n",
       "      <th>state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[jobstreet-my-job-4839088]</td>\n",
       "      <td>Big Data Lead (Work in Singapore) - 44565</td>\n",
       "      <td>SGD 7,000 - SGD 10,500</td>\n",
       "      <td>Job HighlightsExciting future with breakthroug...</td>\n",
       "      <td>Manager</td>\n",
       "      <td>7 years</td>\n",
       "      <td>Full-Time</td>\n",
       "      <td>Bachelor's Degree, Post Graduate Diploma, Prof...</td>\n",
       "      <td>Computer/Information Technology, IT-Software</td>\n",
       "      <td>Keysight Technologies Malaysia Sdn. Bhd.</td>\n",
       "      <td>463532-M</td>\n",
       "      <td>2001 - 5000 Employees</td>\n",
       "      <td>Electrical &amp; Electronics</td>\n",
       "      <td>/en/job/big-data-lead-work-in-singapore-44565-...</td>\n",
       "      <td>data scientist</td>\n",
       "      <td>negeri-sembilan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[jobstreet-my-job-4832121]</td>\n",
       "      <td>SQL Database Administrator (数据库管理员)</td>\n",
       "      <td>MYR 15,000 - MYR 25,000</td>\n",
       "      <td>Job DescriptionJob Requirements: Must speak, r...</td>\n",
       "      <td>Senior Executive</td>\n",
       "      <td>3 years</td>\n",
       "      <td>Full-Time</td>\n",
       "      <td>Bachelor's Degree, Post Graduate Diploma, Prof...</td>\n",
       "      <td>Computer/Information Technology, IT-Network/Sy...</td>\n",
       "      <td>Morivy Data and Technology Inc.</td>\n",
       "      <td>None</td>\n",
       "      <td>1 - 50 Employees</td>\n",
       "      <td>Computer / Information Technology (Software)</td>\n",
       "      <td>/en/job/sql-database-administrator-%E6%95%B0%E...</td>\n",
       "      <td>data scientist</td>\n",
       "      <td>negeri-sembilan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[jobstreet-my-job-4831309]</td>\n",
       "      <td>Korean Content Specialist (Pharmaceutical) Bas...</td>\n",
       "      <td>Posted on 24-Feb-22</td>\n",
       "      <td>Job HighlightsBest Workplace EverCompetitive B...</td>\n",
       "      <td>Senior Executive</td>\n",
       "      <td>1 year</td>\n",
       "      <td>Full-Time</td>\n",
       "      <td>Bachelor's Degree, Post Graduate Diploma, Prof...</td>\n",
       "      <td>Others, Publishing</td>\n",
       "      <td>Clarivate (Malaysia) Sdn Bhd</td>\n",
       "      <td>1360469-D</td>\n",
       "      <td>2001 - 5000 Employees</td>\n",
       "      <td>Consulting (IT, Science, Engineering &amp; Technical)</td>\n",
       "      <td>/en/job/korean-content-specialist-pharmaceutic...</td>\n",
       "      <td>data scientist</td>\n",
       "      <td>negeri-sembilan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[jobstreet-my-job-4852008]</td>\n",
       "      <td>Manufacturing Engineer- Fresh Graduates (1 yea...</td>\n",
       "      <td>MYR 3,000 - MYR 3,500</td>\n",
       "      <td>Job HighlightsCareer AdvancementDaily Meal All...</td>\n",
       "      <td>Entry Level</td>\n",
       "      <td>None</td>\n",
       "      <td>Full-Time</td>\n",
       "      <td>Bachelor's Degree, Post Graduate Diploma, Prof...</td>\n",
       "      <td>Engineering, Electrical, Mechanical</td>\n",
       "      <td>Plexus Manufacturing Sdn Bhd</td>\n",
       "      <td>399136-M</td>\n",
       "      <td>More than 5000 Employees</td>\n",
       "      <td>Electrical &amp; Electronics</td>\n",
       "      <td>/en/job/manufacturing-engineer-fresh-graduates...</td>\n",
       "      <td>data scientist</td>\n",
       "      <td>negeri-sembilan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[jobstreet-my-job-4852655]</td>\n",
       "      <td>Production Executive</td>\n",
       "      <td>Posted 12 hours ago</td>\n",
       "      <td>Job DescriptionJob Summary Responsible for the...</td>\n",
       "      <td>Senior Executive</td>\n",
       "      <td>3 years</td>\n",
       "      <td>Full-Time</td>\n",
       "      <td>Diploma, Advanced/Higher/Graduate Diploma, Bac...</td>\n",
       "      <td>Manufacturing, Manufacturing</td>\n",
       "      <td>SUNSHINE BREAD SDN BHD (Formerly known as Auri...</td>\n",
       "      <td>1219557K</td>\n",
       "      <td>51 - 200 Employees</td>\n",
       "      <td>Manufacturing / Production</td>\n",
       "      <td>/en/job/production-executive-4852655?jobId=job...</td>\n",
       "      <td>data scientist</td>\n",
       "      <td>negeri-sembilan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       job_id  \\\n",
       "0  [jobstreet-my-job-4839088]   \n",
       "1  [jobstreet-my-job-4832121]   \n",
       "2  [jobstreet-my-job-4831309]   \n",
       "3  [jobstreet-my-job-4852008]   \n",
       "4  [jobstreet-my-job-4852655]   \n",
       "\n",
       "                                           job_title             salary_range  \\\n",
       "0          Big Data Lead (Work in Singapore) - 44565   SGD 7,000 - SGD 10,500   \n",
       "1                SQL Database Administrator (数据库管理员)  MYR 15,000 - MYR 25,000   \n",
       "2  Korean Content Specialist (Pharmaceutical) Bas...      Posted on 24-Feb-22   \n",
       "3  Manufacturing Engineer- Fresh Graduates (1 yea...    MYR 3,000 - MYR 3,500   \n",
       "4                               Production Executive      Posted 12 hours ago   \n",
       "\n",
       "                                     job_description         job_level  \\\n",
       "0  Job HighlightsExciting future with breakthroug...           Manager   \n",
       "1  Job DescriptionJob Requirements: Must speak, r...  Senior Executive   \n",
       "2  Job HighlightsBest Workplace EverCompetitive B...  Senior Executive   \n",
       "3  Job HighlightsCareer AdvancementDaily Meal All...       Entry Level   \n",
       "4  Job DescriptionJob Summary Responsible for the...  Senior Executive   \n",
       "\n",
       "  experience   job_type                                     qualifications  \\\n",
       "0    7 years  Full-Time  Bachelor's Degree, Post Graduate Diploma, Prof...   \n",
       "1    3 years  Full-Time  Bachelor's Degree, Post Graduate Diploma, Prof...   \n",
       "2     1 year  Full-Time  Bachelor's Degree, Post Graduate Diploma, Prof...   \n",
       "3       None  Full-Time  Bachelor's Degree, Post Graduate Diploma, Prof...   \n",
       "4    3 years  Full-Time  Diploma, Advanced/Higher/Graduate Diploma, Bac...   \n",
       "\n",
       "                                  job_specialization  \\\n",
       "0       Computer/Information Technology, IT-Software   \n",
       "1  Computer/Information Technology, IT-Network/Sy...   \n",
       "2                                 Others, Publishing   \n",
       "3                Engineering, Electrical, Mechanical   \n",
       "4                       Manufacturing, Manufacturing   \n",
       "\n",
       "                                        company_name company_registration  \\\n",
       "0           Keysight Technologies Malaysia Sdn. Bhd.             463532-M   \n",
       "1                    Morivy Data and Technology Inc.                 None   \n",
       "2                       Clarivate (Malaysia) Sdn Bhd            1360469-D   \n",
       "3                       Plexus Manufacturing Sdn Bhd             399136-M   \n",
       "4  SUNSHINE BREAD SDN BHD (Formerly known as Auri...             1219557K   \n",
       "\n",
       "               company_size  \\\n",
       "0     2001 - 5000 Employees   \n",
       "1          1 - 50 Employees   \n",
       "2     2001 - 5000 Employees   \n",
       "3  More than 5000 Employees   \n",
       "4        51 - 200 Employees   \n",
       "\n",
       "                                    company_industry  \\\n",
       "0                           Electrical & Electronics   \n",
       "1       Computer / Information Technology (Software)   \n",
       "2  Consulting (IT, Science, Engineering & Technical)   \n",
       "3                           Electrical & Electronics   \n",
       "4                         Manufacturing / Production   \n",
       "\n",
       "                                            job_link     search_term  \\\n",
       "0  /en/job/big-data-lead-work-in-singapore-44565-...  data scientist   \n",
       "1  /en/job/sql-database-administrator-%E6%95%B0%E...  data scientist   \n",
       "2  /en/job/korean-content-specialist-pharmaceutic...  data scientist   \n",
       "3  /en/job/manufacturing-engineer-fresh-graduates...  data scientist   \n",
       "4  /en/job/production-executive-4852655?jobId=job...  data scientist   \n",
       "\n",
       "             state  \n",
       "0  negeri-sembilan  \n",
       "1  negeri-sembilan  \n",
       "2  negeri-sembilan  \n",
       "3  negeri-sembilan  \n",
       "4  negeri-sembilan  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_data_scientist = pd.read_feather(path_data_scientist)\n",
    "df_data_scientist.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start cleaning data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Format job id to be numerical\n",
    "df_data_scientist[]"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "cadcdcb536bf306a94042e6d3e2806f549212ffab4cd86c3d91066de65a7cf2b"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('forwardSchool')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
